Type,YouTube,Student,Date,Title,Keywords,Summary,MainLevel,Level1,Level2,Level3,Lecturer,Affiliation,SummaryWordCount,2-4 highlights: no longer than 3 minutes each with a clear one-line description of WHY it's a highlight,,,,,Time spent on each video,"Possible B-Roll, Background Music",,,,COMMENTS
Distinguished Lecture,http://youtu.be/mwnPQOoNKTQ,Generale (9),25-10-2007,Musical Origins: Processing Temporal and Spectral Patterns in Infancy,"Early Development, Music, Brain, Perception, Auditory Development","Across human societies, music remains a universal experience that all of us - young and old - come to experience. From our youngest days as infants, we are exposed to music through the singing of lullabies or rhythm from ""bouncing"". In this Distinguished Lecture, Professor Laurel Trainor talks about the origins of music in a developmental sense - how early can humans recognize and learn rhythm and pitch structures, and do specific musical experiences from childhood affect brain development? Various studies are explored, showing that even infants can be sensitive to consonance and dissonance, exhibit the ability to extract rhythmic, or metrical structure, and that the auditory cortex can rapidly mature between the ages of 2-6 months.","Cognition, Perception and Movement",Perception,Brain,Early Develop,Laurel Trainor,"McMaster University, Canada",114,"(~10:24 - 13:36) Rhythm and Movement in Infants --> A humorous look at infants and their rhythm perception using an experiment with bouncing and an ambiguous rhythm (as either duple or triple meter), closing with data that shows that the way an infant is bounced/moved affect what rhythm they perceive/show preference to (for more information on the ""ambiguous rhythm"" set-up, see 4:33 - 7:35).","(~ 35:44 - 38:50) Learning Musical Pitch Structure: Consonance vs. Dissonance Recognition in Infants --> This highlight, preceeded a few minutes before by some background information on pitch processing and the basiliar membrane, shows infants exhibiting preference for consonance over dissonance as early as 2 months old in a study involving intervals, and a study involving a Mozart tune and it's dissonant version.","(~57:49 - 1:01:27) Can Infants Hear Virtual Pitch? --> Starting with a short introduction to virtual pitch/pitch of the missing fundamental, Prof. Trainor presents data on infants being able to perceive virtual pitch at 4 months old, but not at 2 months old, showing rapid maturation of the auditory cortex in infants after 2 months.","(~1:02:31 - 1:06:00) Effects of Specific Musical Experience on Brain Development --> An extra look into more of Prof. Trainor's work that examines the effect of musical experience on brain development in older children (past infancy). (Note: This was kind of an extra thing she attached to the end of her talk instead of a formal conclusion or wrap-up, so it runs a little longer than 3 min.)",,3h30,,,,,
Distinguished Lecture,http://youtu.be/8mzQRnWAu2A,West (7),17-01-2008,Obstinate systems: Resistance as process in interactive performance,"interactive music, digital musical instruments, Max/MSP, ","Butch Rovan describes several pieces in which interactive audio systems are designed to resist the performers. The obstinacy of these systems is taken as a creative impetus, and the performer must work with—and against—them, finding themselves in a collaborative relationship with these computational co-performers, exploring musical and creative terrain where they might not normally find themselves.","Instruments, Devices and Systems",Interaction,,,Butch Rovan,"Brown University, USA",56,35:45 - 37:15 (1m30s) Studies in Movement #1,12:54 - 13:28 (34s) Rovan talks about one performer's personal experience working with one of Rovan's obstinate systems.,,,,2hr00,"8:55 - 11:30 (2m35s), excerpt from sine hohle Form",16:07 - 19:27 (3m20s) excerpt from Vis-a-Vis,"22:50 - 25:20 (2m40s), excerpt from Collide","43:20 - 44:00 (40s) lovely image, no sound",
Distinguished Lecture,http://youtu.be/GRrElxJkvIc,Martins (8),21-02-2008,Oscillation regimes of musical wind instruments: The points of view of the physicist and the instrumentalist ,"bifurcation schemes, acoustics, clarinet, oscillation regimes, self-sustained oscillations","Depending on the musical instrument, it is possible to produce up to 20 different sounds with one single fingering. This relationship between fingering and resulting sound is determined by the oscillation regimes, which is why it is essential for the musician to learn to control them. Dr. Kergomard shows how these regimes apply to wind instruments, particularly the clarinet. Using different models and bifurcation schemes, he investigates the behavior of sound in nonlinear systems. His lecture includes a review of elementary acoustics, results from an experiment that uses an artificial mouth, and even a theoretical explanation of why clarinets squeak.","Instruments, Devices and Systems",Acoustics,,,Jean Kergomard,"Laboratoire de Mécanique et d'Acoustique, CNRS, France",99,"18:47-19:10 
Watch as an artificial mouth developed in IRCAM (Paris) with latex tubes filled with water is used by Pierre-André Taillard to play the clarinet.","40:09 – 41:14 
Listen to the period doubling phenomenon.",,,,2hr55,,,,,
Distinguished Lecture,http://youtu.be/D5EJLQlUigM,Richardson (7),27-03-2009,Mining for the Meaning of Music,"rhythm, melody, motif, principal component analysis, beat tracker","What does the term ""music"" denote? Can we define music?  As a professor of electrical engineering and leader of the Laboratory for Recognition and Organization of Speech and Audio (LabROSA), Ellis explores large collections of music samples in order to produce “a condensed space” in which to identify and label musical qualities and provide definitions. His extensive research has encompassed drumbeat rhythms and melody analysis. The aim of his melody research is to provide a dictionary of common motifs (clichés) in musical melodies. Additionally, Ellis studies the meanings or labels individuals attribute to music, and this research, in turn, has implications as to how music is to be classified.",Music Information Research,Analysis,,,Dan Ellis,"Columbia University, USA",109,"4:26-5:17 topic of talk: what is denoted by the term ""music""? Can we define music",55:05-55:25 overview of the ongoing research goals,,,,15/05/18 0:15 16/05/18 1:40,,,,,
Distinguished Lecture,http://youtu.be/VjSMna75fxY,Generale (8),17-04-2008,Sound Actions: Human Movement in the Perception and Cognition of Music,"Perception, Cognition, Movement, Music Theory, ","Movement is everywhere: from walking down the street, to hand gestures while speaking, to a musician's movement during a performance. Regardless of musical training and background, humans are observed to spontaneously generate movements that reflect musical features. In this lecture, Professor Godoy reviews various studies on music and movement and how these findings may influence other areas of music research such as music perception cognition and music theory. By examining the link between music and movement, Prof. Godoy speaks on how human movement plays an integral part in music perception and music cognition in general. The lecture ends with a conclusion of topics, as well as issues, concerns, and suggestions for future work.","Cognition, Perception and Movement",Perception,,,Rolf Inge Godøy,"University of Oslo, Norway",113,"(~3:11 - 6:28) Why Study Sound-Related Actions? --> An introduction for the purpose of the lecture, the Motor Theory of Perception (which is referenced repeatedly in this talk; please reference 16:56 - 19:56 for more details on this theory and the link between movement and music theory), and his personal reasons related to music theory as to why he studies movement in music.(Sorry, a few seconds over three minutes, he closes with a long sentence, but it's interesting)","(~21:11 - 26:16) Air Guitar Championships: Motor Components in Music Perception --> An examination, by looking at a video from the World Air Guitar Championships, on how people with little music training/background are still able to pick up on or imitate musical movements.","(~32:15 - 35:06) Listener's Knowledge of Sound-Producing Actions --> An example of humans exhibiting knowledge of musical movement, regardless of musical background using a piano study with a professional, a student, and a tone-deaf person, with the latter showcasing the ability to follow pitch-space, dynamics, and onset of notes.","(~1:10:03 - 1:13:00) Summary, Conclusion, and Future Work --> A nice wrap up of the concepts (motor theory - 16:56, chunking - 47:17, and coarticulation - 58:40) from this lecture, how it can be applied to music theory, its challenges, and where future work needs to be done.",,4h30 (because it was hard to hear…),,,,,
Distinguished Lecture,http://youtu.be/S7AOZIGP9Ys,Generale (7),16-10-2008,Slippery Rocks: A Low-Tech Percussionist Navigates the Crosscurrents of Music Technology,"Percussion, Music Technology, Performance Practice, Performance, Contemporary Music","Percussion and music technology have often been lumped together as ""new technology from the 20th century,"" involving the ""liberation"" or refinement of sound, and largely involving the culture of addition. In this lecture, Steven Schick talks about how concepts regarding percussion and performance might transpose into the realm of music technology. The exploratory and forward-moving thinking of music from the late 20th and early 21st century often driven by creators (such as engineers) and composers, and the process of consolidation - the creation of language and performance practice - often driven by performers is discussed. This lecture examines the role of performer and consolidation, the concept of meaningful limits, and closes with Prof. Schicks musical examples (41:17).",Expanded Musical Practice,Performance,,,Steven Schick,"University of California, San Diego, USA",115 (because of time stamp),"(~4:31 - 7:46) Percussion and Music Technology --> This highlight discusses how the world of percussion might transpose into the world of music technology, as well as the concept of ""additive culture"" and the ""improvishment of sound"" - the latter two of which will be referenced for the duration of the talk. (Note: he fully finishes talking about this at 9:15, which is longer than 3 min, but what he closes with is interesting)","(~14:07 - 17:15) (Never) Stop Exploring--> Prefaced by a short introduction into the creation of meaningful limits (~11:00), Prof. Schick discusses the explorative thinking that drives the creation of new music and the challenges that come with it, the idea of consolidation, and the role of the performer in relation to music technology.","(~26:19 - 29:36) The Role of the Performer --> This highlight further expands on Prof. Schick's ideas on the role of the performer and consolidation in the creating and developing of new music with technology, closing with a personal performance experience of his. (Note: this could also end around 29:54.. Sorry, I know these highlights tend to run a little on the long side, so I tried to pick an endtime that didn't cut off a sentence, but still made sense as an ending, even though he continues.)","(~32:58 - 34:18) Engagement with Technology --> In this highlight, Prof. Schick discusses what is necessary for the longevity and vitality of art, the importance of conversation between practitioners, and the important questions for performers engaging in technology (which leads into examples from Prof. Schick's performance experiences).",,4h00,,,,,
Distinguished Lecture, http://youtu.be/CxFVjKMsaTc,Martins (7),22-01-2009,The voice as a musical instrument,"voice source, tuning formants, vocal economy, formant cluster, voice timbre, fundamental frequency, partials","How do singers produce and project their voice, doing so in a way that reaches different levels of expressivity? In a very didactic lecture, Dr. Sundberg unveils these aspects of singing. He starts with a comprehensive yet concise explanation of the physiological and acoustic components of the voice, especially the tuning formants. Following is a discussion on strategies adopted by professional singers to ensure vocal economy, like the manipulation of the first formant and the formant cluster used by female and male singers respectively. Finally, he investigates three principles associated with expressiveness: tempo changes to mark the structure, intonation variation to emphasize contrasts, and time of tone onset to reinforce important notes.","Instruments, Devices and Systems",Performance,,,Johan Sundberg,"Royal Institute of Technology, Sweden",112,"2:48-3:32
Listen to the single partials of a voice source","8:42-9:31
Interesting demonstration of vowels as a function of vocal tract shape","15:34-17:57 
Informative summary of tuning formants' roles","29:53-32:44 
Listen to the singer’s formant cluster, also known as singer’s spectrum peak, as it is used by operatic western singers.",,2hr20,,,,,
Distinguished Lecture,http://youtu.be/z_sFVFsENMg,Martins (9),19-02-2009,Tonality as a colonizing force in African music ,"tonality, African colonization, Protestant hymn, pre-colonial African soundscape, pygmy singing, pentatonism","Dr. Agawu defines tonality as a “hierarchically organized system of relations animated by desire,” that, according to him, has been used as both instrument of control and creative language. His lecture is centered on the colonizing potential of forms of tonality exported to Africa mainly through the Protestant hymn, thereby affecting the soundscape of costal regions and urban locations. His discussion on the features of the imagined sound of pre-colonial Africa and the responses to European tonality includes musical excerpts from pygmy pentatonic singing, dundun drumming, art music by the composer Joshua Uzoigwe, and new traditional music. All musical examples are thoroughly analyzed, leading to a profound insight into the dynamics of tonal influences.",Music Information Research,Musicology,,,Kofi Agawu,"Princeton University, USA",114,"18:53-19:50 
Listen to the pentatonic pygmy singing – an example of pre-colonial African music","28:36-29:20 
Listen to the dundun drumming, known for their ability to mimic the inflexions of spoken language","32:52-34:56 
Unpublished recording of a song by the Nigerian composer Joshua Uzoigwe performed by his girlfriend and himself. ",,,3hr10,,,,,
Distinguished Lecture,http://youtu.be/UAPEVDPvlE8,Generale (6),26-03-2009,Musical Memories in Normal and Disordered Aging,"Aging, Perception, Cognition, Dementia, Alzheimer's,","Caregivers often report witnessing a positive effect of music on a patient with dementia. While the aging brain may face cognitive difficulties, particularly those suffering from dementia of the Alzheimer's type, normal aging patients as well as those in moderate to severe stages of dementia can exhibit preserved memory for melody and lyrics. In this talk, Professor Lola Cuddy explores the topic of music and the aging brain by speaking on approaches to studying musical memory, with a focus on melodies, the challenges of research in patients with dementia, and her own work. Various case studies and their data are examined, and a brief overview of the work done in this field is explored.","Cognition, Perception and Movement",Perception,,,Lola Cuddy,"Queen's University, Canada",114,"(~2:14 - 5:03) Paradigms for the Study of Musical Memory --> Prof. Cuddy outlines the methods and approaches to studying musical memories, and these concepts will be repeatedly referenced for the duration of the talk. (For some general findings regarding the four paradigms mentioned here, please see 12:26 - 21:12)","(24:13 - 27:15) What About What Caregivers Tell Us (Long-Term Memory)? --> A look into procedural memory and the research challenges in this field of recruiting subjects (for the methods they developed in answer to the research challenges they faced, please see ""Behavioural Observation (~27:28 - 30:28).","(~40:03 - 45:07, can also start at 41:44) Presentation of Data for a Study (Cuddy & Duffin, 2005) --> An examination of data from a study by Cuddy and Duffin that shows encouraging support for the hypothesis that musical memory may be spared and can be reliably assessed (mentioned around ~36:32).  (Also a good intro to box and whisker plots for those who haven't really seen them before. P.S. Sorry, I know this one is waaaay over the 3 min mark for a highlight, but she has some mouse trouble and audience interjection near the beginning, but it's worth it to see what the results show)  ","(~46:08 - 49:07) Concluding Comments --> A wrap up of the concepts and data examined in this talk, as well as areas and questions that are yet to be further explored and answered. (Note: worth it to go until 50:21 for the full wrap-up)",,3h00,,,,,
Distinguished Lecture,http://youtu.be/XLBOBMY_vDQ,Rong (4),16-04-2009,Music and emotion: Toward Computational Models of Empathy and Entrainment,"emotion, society, research, computation","Camurri provides a one-of-a-kind insight into the ground-breaking research he is currently conducting at Italy's University of Genoa, which involves examining the relevance of the performing arts and their potential contribution to the progression of technology and science. He has done much of his work with dancers, getting them to express various emotions through the same choreography and studying how automatic recognition programs allow us to electronically interpret their movement. With this kind of information, he is then able to extrapolate something much bigger: the understanding of empathy and synchronization between people in social environments.","Cognition, Perception and Movement",Psychology,,,Antonio Camurri,"University of Genoa, Italy",95,"13:30-14:24 One of his early research projects analyzed dance languages and the works of choreographers, to see if he could use the connection towards robotic programming. ","33:50-36:50 Five dancers were asked to perform the same choreography four times, each time with a different emotion (anger, fear, grief, joy). Camurri then used a Processing program to analyze their movement, comparing it with the ratings provided by human spectators.","41:37-42:50 By examining how movement correlates with emotion, it was found that two characteristics played a crucial part in musical emotion and interpretation: the motion of the upper body and velocity of head movements.","57:13-59:30 The communication and synchronization between musicians playing together in an ensemble creates a situation where emotions can be either simulated or induced, and then analyzed using measurements like eye contact and body language. ",,3hr,,,,,
Distinguished Lecture,http://youtu.be/UN_j04vyvS0,Rong (7),24-09-2009,Learning structures in natural sounds,"evolutionary biology, computer science, technology, programming","Lewicki looks at the processing of sound in two facets: the digital processing and analysis of audio tracks (engineering), and the physical structure of human aural mechanisms, the ear (physiology). Because his work deals with both physics and biology, he must find a way to reconcile both familiar laws of physics as well as logic of evolutionary biology as it applies to humans. Like many others, he uses theoretical models from nature to form efficient coding theory - and eventually uses this to learn about higher-order structure. In other words, computer programming is used to analyze sets of audio data from the biological world, which can then tell us about physical structures of organisms that evolved.","Cognition, Perception and Movement",Biology,,,Michael Lewicki,"Case Western Reserve University, USA",115,"5:08 -7:22 Extremely detailed measurements can be done by taking a specific soundwave and seeing how the human ear responds - researchers can use electrodes that measure electrical activity in response to the sound, tracing it to the auditory nerve that carries the signal up to the brain. Through this, they've been able to approximate some ""filters"" that we use to sense sound - for instance, a very loud sound will have a specific frequency wave with a slow decay.","13:02 - 15:51 The evolution of eyes based on Darwinism was set in place in order to ""solve a problem"". Over several million years, new membranes evolved with new functions, but they all came to be within a template that solved our need to be able to visually perceive the world around us. This is why most seeing organisms have eyeballs that are round, with circular lens, because they evolved to fit the same need. We can use this model of ""problem solving"" to similarly observe how our auditory physiology evolved.","26:40 - 28:25 Computer programming is used to extract and code specific speech consonants, the process of which uses algorithms and Fourier and wavelet transforms to measure coding efficiency. If this kind of model is extended to the sounds that biological organisms have evolved to process, then we should be able to make predictions on the structures of the organisms themselves. ",49:58 - 52:54 The most difficult part of a speech recognizer is recognizing consonants - vowels are recognized with a much higher success rate than consonants. The struggle to improve upon this has led to things like modelling impact sounds of hitting a metal bar and seeing how the waveforms differ upon each impact (natural variability) to attempt to recreate these sounds computationally.,,3hr30,,,,,
Distinguished Lecture,http://youtu.be/rn2_fFcRZlY,Martins (10),25-10-2009,The sound of orchestras and soloists as a combination of room acoustics and acoustical properties of the musical instruments,"acoustics, sound radiation, acoustic properties, orchestra's seating arrangement, decay, loudness, synchronicity, sound level, masking effect","When it comes down to understanding the resulting sound of a musical performance, Dr. Meyer shows that there is much more to be considered than what musicians usually pay attention to. The room acoustics and the acoustic properties of the instruments, he explains, have an impact on the sound impression of the listener. His lecture includes an encompassing discussion on reverberation, decay times of multiple instruments, loudness curves, synchronicity (rhythmic precision) in chamber music, and sound radiation. Based on acoustical and artistic arguments, he also addresses the differences between the German (classical) and the American orchestral seating arrangement. Lastly, he discusses the acoustic demands from the point of view of the performer and the conductor.","Instruments, Devices and Systems",Acoustics,,,Jurgen Meyer,"University of Music Detmold, Germany",115,"38:05-40:52 
Dr. Meyer uses musical examples to support an artistic argumentation in favor of the classical seating arrangement of the orchestra","42:30-44:03 
Understand the masking effect that happens in the orchestra, between violins I and II.",,,,3hr25,,,,,
Seminar,http://youtu.be/R5ldbfhJV3A,Rong (5),02-11-2009,From 45's to downloads,"record producer, development, digital music","Phil Ramone, legendary music producer and engineer, illustrates the journey of his career from a young violinist to a successful record maker and studio owner with over 50 years of experience in the industry. Alongside his numerous stories of working with stars including Frank Sinatra and Billy Joel, he describes the process of learning his craft through apprenticeship and innovation. Despite his roots in traditional music formats, he embraces the development of digital music with positivity - it's a ""new beginning"", and he insists that future generations need to have the best music with the best sound made available.",Music Information Research,Recording,,,Phil Ramone,"Record producer, USA",98,"2:45-2:55 Ramone felt attached to the fact that by limiting the capabilities of the violin to classical styles, there was much more to be discovered and used.","11:52-12:55 The early 60's rock and roll scene was where Ramone got his start, alongside musicians who were willing to record ""illegally"" (past 10pm, when the union had declared it forbidden to use the booth). Times have changed dramatically since then.","40:45-41:00 Ramone came to the biggest change in his career in the 80's, when everything was changing in an era of revolution and technology. 5-inch CDs were beginning to replace 12-inch discs.","44:28-47:28 Ramone was able to convince Frank Sinatra to record the last album of his life, a collection of duets, claiming that singing songs he had already recorded would be a completely different experience after so many years.",,3hr30,,,,,
Distinguished Lecture,http://youtu.be/VOYWnUEq7yA,Rong (6),19-11-2009,Music again: Perspectives on repetition in music,"repetition, analysis, perception, classical, songs","Repetition - it is a defining characteristic of music, yet this seems to be the only form of artistry where it is commonly seen and even welcomed. It's what makes music social and shareable, and allows for the creation of interpersonal cohesion - well-known nursery rhymes are sung early on by children, for example, and the familiarity of old pieces of music provides comfort and a link to past memories. Margulis talks about her intuition for why the first notes of one's favourite song might spark their excitement, and how repeating motives might exist to serve as connections to people and things in the real world - as well as differentiating and bringing attention to otherwise unnoticeable elements.","Cognition, Perception and Movement",Analysis,,,Lisa Margulis,"University of Arkansas, USA",114,"3:16-3:30 Repetition in music comes in two sorts: both within a particular piece of music, and our tendency to reexpose ourselves to the same familiar pieces of music voluntarily. It is interesting as she further notes that our enjoyment of these kinds of repetition are similarly related when examined from a cognitive science viewpoint.","11:38 - 13:12 Earworms tend to play over and over in one's head, and this is often due to the brain's need to play it until a point of rest. In this way, certain tunes - which are snippets of music with trajectory and time, as opposed to singular harmonies or pitches - have a ""stickiness"" that is captured by the brain. This essentially sets up a repetition that links the music to previous recollections of hearing the tune. ","23:38 - 24:01 There is no thing as true redundancy when an element is repeated; at minimum, it will sound different based solely on the context as well as the fact that it has been heard before. Even if a series of identical hammer strokes were to be played, each one would cause the unfolding of a sequence where they all possess different qualities of continuation. This can lead to a phenomenon where attention is drawn to a quiet repetitive element.","40:00 - 42:48 By repeating a certain segment over and over, such as in The Reaper's Song by Rameau, we are eventually forced to listen to it very carefully and break it down into smaller components that might begin to sound incoherent and nothing like the original moment. It plays with our brains' perceptions of what the sound byte originally was, and has deeper implications in things such as repeats in classical sonata form.",,3hr 30,,,,,
Distinguished Lecture,http://youtu.be/Vzf19l-Ztsk,Richardson (8),21-01-2010,Does Music Make You Smarter,"mozart effect, intellectual benefit, music lessons, psychology ","The popular theory of the “Mozart Effect” states that listening to the music of Mozart increases intellectual ability by priming the brain. Schellenberg presents research-based conclusions concerning the idea of unique intellectual benefits surrounding music listening and music lessons. His research has uncovered a “Schubert Effect” associated with listening to the music of Schubert and even a “King Effect” from listening to a Stephen King audio book. Schellenberg concludes that music, among other such “catalysts”, can affect arousal and mood, which, in turn, affects performance on intellectual tasks. Further, unlike other common out-of-school activities, music lessons are associated with small but broad intellectual benefits. ",Expanded Musical Practice,Psychology,,,Glenn Schellenberg,"University of Toronto, Canada",103," 1:41-2:09 The question of whether music makes one smarter is only valid if listening to music is in some way special. Continue to 2:42 to include ""Does exposure to music include non-musical benefits?"" In my opinion, this extended version is a bit less interesting.","43:57-45:26 Benefits associated with music lessons (Music lessons are associated with increases in IQ,  the association is not attributable to extraneous variables that are associated with taking music lessons and with IQ, the  association is small but long-lasting, the association has applied relevance that extends beyond IQ testing to academic achievement but not to g or to social-emotional abilities, comparable nonmusical activities do not have similar consequences, although they may have other developmental benefits (e.g., social consequences of drama lessons). Most likely, those with higher IQ are more likely to take music lessons.","46:33-48:01 He offers further explanations for the existence of the IQ increase of music training: studying music is like learning a second language, music lessons provide training in a variety of multiple areas (motor skills, reading, emotions, etc.), and/or abstract nature of music.","48:00-48:32 1) Like many other experiences, listening to music can change how you feel, and how you feel affects behavior, including intellectual functioning. 2) Unlike other common out-of-school activities, music lessons are associated with small but broad intellectual benefits.  ",,24/04/18 1:15 26/04/18 0:40 ,,,,,
Distinguished Lecture,http://youtu.be/wf_FfC9Uq3U,Richardson (9),25-03-2010,Reverse Engineering the Violin,"reverse engineering, violin, instrument design","Have you ever wondered exactly why violins are made the way they are? What aspects of the modern violin lend themselves to the instrument’s sound, strength, and durability? What could we do differently were we to re-invent the violin? Woodhouse provides an engineer’s perspective as he explores such questions and offers unique insight on the design and possible future re-designing of the violin. He presents the audience with a variety of considerations on details such as the impedance of materials, types of wood and glue, the use of arches, purfling, and slots (f holes) in the design of the instrument, and more.","Instruments, Devices and Systems",Design,,,Jim Woodhouse,"Cambridge University, UK",102,0:24-1:50 Goal/content of the talk: reverse engineering the violin,14:37-14:46 What governs how loud the instrument is (speed that energy moves from string into the body of the instrument),58:08-59:17 ending illustration on how he has shared the easier parts of the scientific puzzle and more information must be filled in,,,27/04/18 1:20 30/04/18 0:25,,,,,
Distinguished Lecture,http://youtu.be/qvTqte1nFf8,Rong (8),15-05-2010,"Cognition and control in human-machine interaction, auditory communication, and orchestral conducting","engineering, robotics, cognition, audio","This lecture explores some of those most interesting domains of human interactions with machines, where human sciences, system sciences, and information sciences come together to create Human Machine Systems. Johannsen, who has done over 40 years of research in this discipline, describes the engineering that can be developed from the field of orchestral conducting, and the autonomy and flexibility we can learn from observing music in performance. He addresses auditory communication, both through talking with words and with other sounds or music, as tools we can use to design and improve engineering processes like air traffic control.","Instruments, Devices and Systems",Interaction,,,Gunnar Johannsen,"Universität Kassel, Germany",97,"11:12 -  14:12 Control is divided into three subcategories: manual control, where human cognition is dominant and is responsible for things like tracking and action planning; supervisory control, including activities like teaching and diagnosing; and gestural control, seen in activities like conducting where manual movement controls a greater process. ","17:53 - 19:06 The importance of mental images in one's mind paves the way for conscious understanding, planning and navigation. In a conductor's mind, a mental image of the orchestral work will determine the set of their gestures, as well as their expressiveness, in the supervisory control that they have. A mental model of any musical work involves its basic structure, themes, variations and transformations of the theme, and their relationships overall.","31:46 - 34:23 He offers the example of car driving as an illustration of the multi-level system interaction involved: there is human interaction with themselves as they form a mental image of where they want to go, as well as human-machine interaction as they gesture with their body, controlling the movement of the automated machine (car). Different proportions of these two controls leads to more or less responsibility of the driver for the vehicle, and this has an implication for technologies lik self-driving cars.","47:24 - 49:50 For moving robots, auditory symbols For example, a broken ascending triad would represent moving upwards in a plane for the robot, while going down would be indicated by a descending triad. Left and right movements are symbolized aurally by patterns of tones with different rhythms. The robot would use these sounds to orient itself whichever way they indicated.",,4hr00,,,,,
Student Symposium KEYNOTE,http://youtu.be/pibOuaot0SE,West (8),27-05-2010,Interaction in the Post-Convergence Age,"sensors, ubiquitous computing, analog modular synthesizer, digital musical instruments","Joe Paradiso gives an extensive tour of his impressive home-made modular synthesizer studio, and presents a few of his digital musical instruments. Paradiso shares his enthusiasm, and practical insights, toward more expressive and intimate control of live electronic music. Although much of his work starts in a musical context, Paradiso shares some of the ways in which the technological material of his digital musical instruments comes to be used in other sometimes unexpected places.","Instruments, Devices and Systems",Interaction,,,Joe Paradiso,"Massachusetts Institute of Technology Media Lab, USA",74,5:40 - 6:36 (56s) Paradiso makes a connection between his work with high energy particle accelerators and his later work with sensor networks and digital musical instruments,13:36 - 13:48 (12s) great picture of enormous modular synthesizer in Paradiso's living room circa mid-1980s,54:37 - 55:30 (53s) an example of a non-musical use of sensor technology made for a musical application: automatic HVAC control to make people more comfortable while using less energy,50:53 - 54:13 (20s) sensor controlled algorithmic rave music,,1hr00,14:36 - 15:07 (31s) splendid modular synthesizer sound sculpture,,,,
Distinguished Lecture,http://www.youtube.com/watch?v=dUcNzPhZdwk,Richardson (10),16-09-2010,Sound Synthesis Based on Physical Models,"physical modeling, vibration, synthesis","Smith offers the unique combined perspective of a professor of music and an electrical engineer, who is based in the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University. Organizing the current research in it’s historical context, Smith discusses the historical roots of sound synthesis based on physical modeling dating back to Bernouli's ingenious insight into superposition of simple modes of vibration and d'Alembert's foundational superposition of traveling waves, which was essentially the first wave equation and occurred during Bach's lifetime. Beyond the history of physical modeling, Smith discusses techniques of physical modeling synthesis techniques and shares related research at CCRMA. ","Instruments, Devices and Systems",Modeling,,,Julius Smith,"Stanford University, USA",104,3:08-4:08 history/beginning of modeling,8:38-9:55 replicating a plucked string sound,13:34-14:15 ear design: breaking sound down into frequency components. The ear is a kind of fourrier transform.,1:02:32-1:03:12 and 1:03:56-1:04:13 (he got on a tangent about when Bach was born in the middle) Summary of talk content,,01/05/18 0:45   04/05/18 0:50,,,,,
Xenakis Conference KEYNOTE,http://youtu.be/P997_D4JV7c,Reesor (3),01-10-2010,Xenakis: Arts/Science,"Iannis Xenakis, electronic music, computer music, UPIC, polytope","A close collaborator of Iannis Xenakis' and co-author of his last book, “Music and Architecture,” Sharon Kanach describes the past and ongoing projects that are dedicated to the promotion and development of the Xenakian legacy. Kanach describes exciting projects across Europe and North America, especially highlighting the Xenakis Project for the Americas, which started in New York as an outreach to the general public, and the Centre Iannis Xenakis at the University of Rouen, which formed to create and preserve inventory of the composer’s research and creation. Kanach calls attention to the issues which can arise when performing Xenakis’s works and suggests next steps for contemporary scholars. ",Expanded Musical Practice,Composition,,,Sharon Kanach,"Centre Iannis Xenakis, France",107,Description of the first site-specific re-creation of the controversial Polytope de Persépolis and the concerns involved (21:10-23:15),Activities in progress at the Centre Iannis Xenakis (27:50-30:30),Ongoing and forthcoming publications (35:50-38:30),Next steps for contemporary scholars (39:10-40:15 and 41:00-42:30),,3hr00,Polytope Persepolis: https://www.youtube.com/watch?v=rkGwlb6sONg,"Polytope Persepolis, remixed by Daniel Teruggi (composer and researcher at the Paris Conservatory); interesting because Kanach speaks to ongoing evolution of the performance Xenakis' works: https://www.youtube.com/watch?v=S-GEbbgT5Io&t=193s",,,
Distinguished Lecture,http://www.youtube.com/watch?v=O8Gn54sx_Xw,Reesor (4),21-10-2010,Understanding music on the web: A Yahoo! perspective,"Yahoo! Research, music-information retrieval, machine learning, data ambiguity, model building","In the last decades, the volume and multi-media usage of online music use has exploded. Personalized data from photos, videos, ratings, tags and posts is now abundantly available, resulting in rich yet “noisy”, or context-dependent data. Many tools using this data for user and advertiser satisfaction are no longer adequate. In response, Yahoo! Research is developing tools to increase and improve data. Slaney details these tools and advocates for a “more data wins” approach to data collection, so that one can have more ways to look at, and make judgements about, data or prospective solutions. Discussion is centred around machine learning tools and model-building designed to sift through the vast swaths of data.",Music Information Research,Music Information Retrieval,,,Malcolm Slaney,"Yahoo! Research Laboratory, USA",113,Data labelling and using MIDI data to train HMM models for speech and music recognition (17:00-20:00).,Solving word-use ambiguity in online tagging with word histograms (23:20-26:00).,"Locality Sensitive Hashing: a web search tool borrowed for audio searching, which organizes large pools of data according to their similarity to each other (42:20-44:20).",Determining music similarity by user ratings (48:10-51:10).,,4hr00,,,,,
Distinguished Lecture,http://www.youtube.com/watch?v=uGASpqTXz4g,West (9),25-11-2010,Designing musical instruments that privilege improvisation,"digital musical instruments, mapping, sensors, algorithmic music","In this wide ranging talk, David Wessel discusses his and his colleagues work in the design of digital musical instruments, interactive music systems, and futuristic sensor systems. From questioning what makes a digital musical instrument appropriate for live improvisation, to techniques for complex interface-to-sound mappings, to e-textiles, to loudspeaker design, and even hearing aids, Wessel's research touches on a variety of subjects and application areas. With a pragmatic focus, Wessel offers his perspective on these subjects, the guidelines he has learned for himself, and his vision of what is next to come.","Instruments, Devices and Systems",Design,,,David Wessel,"University of California, Berkley, USA",92,18:05 - 19:16 (1m11s) Wessel insists on the importance of visible effort in live electronic music performance,"19:51 - 20:51 (1m) Wessel talks about the limitation of triggers, arguing in favour of shaping sound continuously",,,,1hr00,"43:02 - 47:45 (4m43s) musical excerpt (audio isn't great, but might make an okay backdrop?)",,,,
Fulbright Seminar,http://youtu.be/C2XKzCQ_Uj4,Gjerbic (3),13-01-2011,"Music, gesture, and musical grammar","musical gesture, musical grammar, physical gesture","Threading together music, movement, and grammar, Lawrence Zbikowski argues that musical gestures are sonic analogues of dynamic processes. Tracing the motion of a leaf falling through the air with your hand is an example of a physical gesture representing a dynamic process: everyone understands that your hand only represents the leaf, but the gesture perfectly encapsulates the motion. Zibikowski suggests that the pairing of musical and physical gestures represent dynamic processes central to human experience, forming musical grammar. Musical gestures exist in a well-defined context—meter and pitch space—so their measurable properties can lend meaning to corresponding physical gestures.","Cognition, Perception and Movement",Gesture,,,Lawrence Zbikowski,"The University of Chicago, USA",100,Zbikowski discusses the respective functions of langauge and music (19:10-19:51),"Musical gestures are anchored by metered rhythms and networks of pitch relationships, giving these gestures a frame of references (33:49-34:53).",,,,3hr00,,,,,
Distinguished Lecture,http://youtu.be/ii6VtnUVsok,Gjerbic (4),17-02-2011,Building Musical Minds in 18th Century Naples,"schemata, musical patterns, 18th century composition","Beginning with the conservatory tradition of 18th century Naples, Robert Gjerdingen discusses the use of schemata in improvisation and composition. Schemata are stock harmonic patterns, a lexicon of solfegi melodies and partimenti bass patterns that permeated 18th and 19th century music. Learning the schemata allows practitioners to build a phrasacon of musical idioms, and gain an understanding of the collocation (how the material fits together) and appropriate frequency of the different patterns. In this tradition, practitioners learn a corpus of coherent utterances, as to not only grasp the mechanics of the patterns, but learn the style of the musical tradition.",Expanded Musical Practice,Composition,,,Robert Gjerdingen,"Northwestern University, USA",100,"Gjerdingen compares stock pattern composition in the 18th century to ice-skating routines, as listeners expected these patterns to occur over the course of the composition (23:10-24:17).","Gjerdingen frames schemata in terms of musical grammar, idioms, and corpi, and discusses if schemata can be used to teach classical music (45:37-46:53).",,,,3hr00,,,,,
Distinguished Lecture,http://www.youtube.com/watch?v=nOv30rHV7Ds,Richardson (11),17-03-2011,Music is Meant to be Heard: Perception is Central in (my) Computer Music,"psychoacoustics, perception, computer music, sound synthesis","The current capabilities of technology, combined with the present progress in research, provides composers with an expanded sonic realm. Pioneering contributor to computer music, Risset, explores the possibilities of computer sound synthesis in composition. Beyond this topic, he delves into the psychoacoustics of sound: how we interpret what we hear. Risset shares how modern computer sound synthesis has ushered in new and varied possibilities that are increasingly congenial to our senses. As Risset proposes, there seems to be an aspect of magic in music that can be enhanced by using the somewhat extreme features of perception involved in synthesis.","Cognition, Perception and Movement",Perception,,,Jean-Claude Risset,"Laboratoire de Mécanique et d'Acoustique, France",99,3:31-5:03 history of synthesis,13:53-14:09 why research is need in computer music,1:23:59-1:25:06 demonstration of one performance/compositional technique ,1:25:06-1:26:15 closing statements and mention of the magic in music,,13/05/18 1:10 14/05/18 0:20 15/05/18 10,,,,,
Distinguished Lecture,http://www.youtube.com/watch?v=6B4CsSwAyqE,Rong (3),15-04-2011,The Compositional Control of Sound Synthesis: from Traiettoria to OMChroma,"composition, sound perception, cognition, tone, synthesis","Synthesis - it's not just about making sound, but rather a way of thinking and hearing, and being sensitive to time. This is what Marco Stroppa has done a lot of thinking about, and he has spent his research work experimenting with acoustic piano sounds and their resonances - and also the complex process of digitalized composing not with these exact sonorities but unique ones inspired by them. As a composer with much experience and knowledge in piano techniques and instrumentation, he dives into the technical details of creating ""pure"" and ""noisy"" tone, as well as artistic lines and creativity. Compositionally, he gives the possibilities and choices of sound synthesis and cognition a great deal of consideration.",Expanded Musical Practice,Composition,,,Marco Stroppa,"Musikhochschule, Stuttgart, Germany",114,"9:00-9:13  ""Perceptual digression"", or how a listener would perceive sound, is determined by two factors: to be stable, the data must be coherent and sufficient. If there is too much data (audio or otherwise), it is simply just perceived as noise.","21:15-22:20 Some issues that Stroppa has run into are the difficulties of organizing sonoric material so that his music has the intended effect on listeners. Different timbres are in different states of perceptual fusion in the brain, and there is a distinction between identifying and simply recognizing. ","28:40-31:14  Sound is perceived in a 3D environment, but it is not easy to imagine it this way. Every distinct voice in a recording adds a layer that enhances or builds upon the music. There is sound in space, and also space in sound.",,,3hr30,,,,,Highlight 3 has no end time?
Distinguished Lecture,http://www.youtube.com/watch?v=F-QNEviNkKw,Gjerbic (5),21-04-2011,Relations between linguistic and nonlinguistic sound systems: Emprical studies,"timbre, tabla drumming, non-lingusitic systems","Neurolinguist Ani Patel argues that in the North Indian tabla drumming tradition, there exists non-linguistic symbiotic relationship between the drum timbres and bols, syllables used to vocalize a drum stroke. Each stroke is created quasi-linguistically via variation in place and manner of articulation, and each bol represents a stroke. Patel argues that bols are a case of “sound symbolism”: in tabla drumming, musical timbres are both reflective by and reflective of speech timbres. Using empirical data, Patel suggests that for experienced drummers, the areas of the brain know to be activated by speech would also be activated by tabla timbres.","Cognition, Perception and Movement",Perception,,,Ani Patel,"The Neurosciences Institute, USA",100,Tabla drummers use different drum strokes to create distinct timbres (8:47-10:17).,"Patel introduces a study investing if bols reflect the timbre, as well as the timing, of drum strokes (17:58-21:04).",,,,3hr00,,,,,
Distinguished Lecture,http://youtu.be/0ClNpyKVXpM,Richardson (3),09-01-2011,Facial and Bodily Gesture in Musical Rehearsal and Performance,"movement, expression, gesture","Davidson explores the link between biomechanics and musical structure: ""How do biomechanical requirements interface with the model of musical performance?"" Her research grapples with the use of motion in musical expressivity during musical performance as evaluated by musicians and non-musicians. Is there an expressive repertoire of gestures, and if so, how are they used? Her research suggests that musicians develop a personal musical movement repertoire within a socio-cultural context. Beyond discussing this repertoire of expressive movements and how it is put into use, Davidson invites us to consider what social studies can add to this discussion.","Cognition, Perception and Movement",Gesture,,,Jane Davidson,"University of Western Australia, Australia",96,"40:33-41:44 there is a rep of gesture unique to each indiv, gov by socialcultural rules or 40:35-",41:48-42:22 How can we look at sociocultural factors and individual meaning of gestures? ,"58:32-1:21 Gesture in socialcultural contest: communicates authenticity. It can also  demonstrate proximics, such as intimacy.",1:02:07-1:02:45 The evolution of her research focus over time.,,1:25,,,,,
Distinguished Lecture,http://youtu.be/DTXyxdeTAnM,Martins (3),27-10-2011,Between art and science: Studying music as performance,"music performance, musicology, schenkerian analysis, performance style, close listening","How can art and science mutually inform one another? Watch how Dr. Cook answers this question with an approach that combines empirical methodologies and cultural interpretations. Using Schubert’s impromptu Op. 90 nº3 and Chopin’s Mazurka Op. 63, he explains how close listening of recordings ""can open up a dimension to which both music theory and music psychology are insensitive, which is that of historical change"". The lecture includes one of the first schenkerian analysis made by Schenker himself, and new analytical techniques capable of extracting timing and dynamic information. Results show that phrase-arching elements are subjective to historical change, yet data is still insufficient to establish a performance style as a historical entity.",Expanded Musical Practice,Analysis,,,Nicholas Cook,"University of Cambridge, UK",113,"6:53-8:07
The undiscussed historical dimension of schenkerian's performance pedagogy","10:35-11:30 
Cook's analysis of Eugene d'Albert's interpretation of Schubert's impromptu nº 3.",,,,3hr15,,,,,
Distinguished Lecture,http://youtu.be/cNxutfofwCs,Gjerbic (6),19-01-2012,Of pipes and patches: Making music on the augmented organ,"organ, augmented instruments, video agumentation","Church organs are immobile instruments, built specifically for the acoustics of their church. D’Alessandro discusses the challenges of augmenting a church organ with electronics for live-electronic performances. Each instrument is voiced for the room, meaning that each of the pipes is carefully balanced with one another to create the desired sound in the hall. In order to augment the instrument electronically, d’Alessandro captured the sound inside of the pipes. He discusses how he used that signal to alter the sound in the hall through various effects and how he used the signal visually, as projected lights onto the pipes.","Instruments, Devices and Systems",Design,,,Christophe d'Alessandro,"CNRS, France",99,D'Allesandro discusses methods of digital augmentation of the organ (24:19-28:28).,This clip shows a video of J.S. Bach's D minor toccata played on the augmented organ. (51:09-52:10),,,,3hr00,,,,,
Distinguished Lecture,http://youtu.be/gfXM1Q7d6Bk,Martins (4),16-02-2012,Large-scale music audio analysis: E-science or e-musicology?,"MIR, music information retrieval, audio analysis, ground-truth","Music information retrieval (MIR) started in the 60's but endless discussions on how to convert music scores into formats that computers could process nearly extinguished the research area. With the advent of audio formats such as mp3 and hard drives with increased storage capacity, new possibilities emerged. Electrical engineers and computer scientists started working on new ways to analyze music. Dr. Downie is a key figure in the evolution of this interdisciplinary science, involved in several initiatives that were responsible for the advancement of large-scale music audio analysis. Developing tools to identify form, structure, and classification of music, this resource empowers musicologists to approach their work in unprecedented ways.",Music Information Research,Music Information Retrieval,,,J. Stephen Downie,"University of Illinois, USA",109,"52:32-54:08
How do engineers use algorithms to deduce structure in music?","1:06:25-1:08:05
When will computers replace humans in the audio analysis process?",,,,2hr25,,,,,
Distinguished Lecture,http://youtu.be/pDQXYyKP1BY,Richardson (4),12-02-2013,Kinematics of Music Cognition,"movement, dance, personality, gender","Even from infanthood, humans have a predisposition to move in response to music. Toiviainen discusses how the presence of a regular beat promotes activity in the motor areas of the brain and demonstrates a view of brain regional activity during music listening. Other topics presented include embodiments of meter in music induced movement (MIM), musical characteristics and MIM, listener characteristics and MIM, and perception of MIM. His findings suggest the metric hierarchies that exists in music are embedded in MIM. Characteristics of the music, such as pulse clarity and the emotional quality of the music tend to produce corresponding movements. MIM also encodes personality traits, emotion, and gender.  ","Cognition, Perception and Movement",Perception,,,Petri Toiviainen,"University of Jyväskylä, Finland",108,12:27- 13:04Four music induced movement research topics he has pursued. ,44:06-45:10 Conclusions of research presentation on the 4 topics.,,,,1:25,,,,,
Distinguished Lecture,http://youtu.be/06TErgm_iZg,Aspinwall (8),14-11-2013,"Drawing sounds, listening to images: The art of time-frequency analysis","time-frequency analysis, DSP, music technology, mathematics, Fourier transform","In this lecture, Patrick Flandrin highlights how time-frequency analysis lies at the intersection between physics, computer science and mathematics. He presents a plethora of approaches to signal analysis and reconstruction that are based on models that range from microphysical (quantum mechanics) to astrophysical (gravitational waves). Throughout this lecture, Mr. Flandrin compares various functions and explains specific applications for each.","Instruments, Devices and Systems",Analysis,,,Patrick Flandrin,"CNRS & Ecole Normale Supérieure de Lyon, France",59,[16:56 - 18:05] The basic framework for analysing music notation,[48:46 - 51:46] An application of time-frequency analysis used in astrophysics,[1:15:34 - 1:16:34] Concludes the talk and explains in simple terms why these type of analysis are useful in the field,,,4h,,,,,
Student Symposium KEYNOTE,http://youtu.be/GtSCVqIDl-k,Tirumala (3),23-05-2012,On the Psycholophysics of Musical Expressivity,"Expressivity, Psycophysics, autism, Psycophysical expressivity curve, Disklavier, MIDI, Piano performance, Piano expressivity.","Daniel Levitin and his team explore ways to quantify the expressivity of a musical performance. With the help of Yamaha's Disklavier,  Daniel and his team artifically produce less expressive versions of musical excerpts. These are then rated for expressivity in a controlled study. Daniel and his team observe various trends that connect expressive performance to variations in dynamics and timing of the performance. Further investigations show that beyond a point, the variation doesn't continue to translate into an expressive quality. The team also explores the same conditions in autistic children, where the study shows that people with autism are unable to determine expressivity in performances from timing and dynamic variation.","Cognition, Perception and Movement",Psychology,,,Daniel Levitin,"McGill University, Canada",110,"18:16 - 19:58: Illustration of stripping away expressivity from an expressive excerpt, using the Yamaha Disklavier technology. Sonic excerpts allow one to gain a first hand insight into how the test was performed.","25:51 - 27:06 - Interpreting initial results on expressivity. Daniel shines a light on where the difference in expressivity is most percievable, and brings insight to the finding that there needs to be at least 50% expressivity before people can discern a piece to have an expressive quality, on a scale ranging between total mechanical performance, and the original expressive recording.","32:07 - 33:40: Extrapolating and artificially introducing more expressivity into a performance than there initiallly was. Audible excerpts give a sense of what introducing more expressivity would sound like, in order to understand how it influences our understanding of expressive. The goal is to answer the question, would a piece that was artificially enhanced in expressivity be perceived as more expressive?",36:04 - 36:45: Superimposing results of non-autistic listeners to autistic listeners yields interesting results which gives reason to believe that autistic listeners don't respond to the same emotional/expressive cues in music in comparison to the average listener.,,2hr,,,,,Too many keywords
Student Symposium KEYNOTE,http://youtu.be/ZLACjtOpe0Q,Tirumala (4),23-05-2012,Design Choices for Computer Instruments and Computer Compositional Tools,"Design Philosophies, PureData, Max, Max/MSP, Miller Puckette, Live Performance, Ableton, Computer Music, Computer Music Tools, Design environments","Early music technology pioneer, Miller Puckette, extrapolates from his experiences in creating the widely acclaimed  environments Max and PureData as music processing tools. While addressing the longevity of such tools, amidst the evergrowing number of new environments, which are largely similar in their capabilities. Stressing on the futility of developing more of such environments, he compells for a shift away from the composer-centric nature of the existing tools, by harnessing more recent technological advancements. On that subject, Miller highlights the absense of a holistic musical programming language that would incorporate the needs of modern music composers, and incorporates the technological robustness of a language like C.","Instruments, Devices and Systems",Design,,,Miller Puckette,"University of California, San Diego, USA",105,"14:11 - 17:16: The role of Electronic Music Tools described as an evolution in time, from once seemingly obvious to growingly opaque. This leads up to the question of redundancy in the music programming environments that already exist today.","23:40 - 25:20: Miller Puckette talks about Transparency as a design objective in the design of Computer Music tools, and how one might unwittingly confine their tool and end up with a tool that isn't really transparent to the user. He presents this idea in the context of trying to be completely invisible as an element in the chain between the designer/composer and the final realised output at the loudspeaker.",31:35 - 33:37: Miller's expresses his views on computer music tools being  biased in favour of using computers as a stage tool or as a live tool. ,37:50 - 39:40: Miller explores the need to explore possible units which could be coded as primitives in the existing design environments so as to implement higher level algorithms into units that can encapsulate a high dimension of sonic possibilities into being controlled or affected through a low dimension of inputs.,,2hr,,,,,Too many keywords; complex summary explanation
Distinguished Lecture,http://youtu.be/8e6R1NFk2qM,Martins (5),21-09-2012,The relationship between musical notation and performance after 1950: Historical survey and theoretical considerations,"musical notation, John Cage, Mario Bertoncini, electronic music, experimental composition, sign and musical sound,","In the second half of the 20th century, new forms of musical notation emerged in experimental compositions. The relationship between sign and sound was affected by new extended acoustic possibilities. Composers saw an opportunity to have an exact sonic representation of their musical ideas without any written notation. For the first time, music could be inscribed instead of prescribed. Interestingly, music scores continued to be used. Dr. Borio explains this “écriture” paradigm in this two-part lecture on the underlying philosophical reasons in the evolution of musical writing. The second part is dedicated to the contributions of Mario Bertoncini on the advancement of John Cage’s multidimensional use of signs, including a live performance by Bertoncini himself.",Expanded Musical Practice,Composition,,,Gianmario Borio,"University of Pavia, Italy",115,"30:00-32:00
Mario Bertoncini's live performance of one of his experimental compositions for piano solo.","55:51-58:00
Recording from 1967 of the improvisational group Nuova Consonanza.","1:09:13-1:10:28
Borio's description of Bhèri, an audio-visual piece for six Japanese gongs written by Bertoncini.",,,4h,PUT ONLINE WITH THE DOCUMENT FROM BORIO TO HELP WITH LECTURE,,,,
Distinguished Lecture,http://youtu.be/yqrsL6fntkQ,Richardson (5),22-11-2012,Imitating Stradivarius,"violin, Guarneri, tone replication, electronic violin","There is a substantial difference in tone quality between a novice playing the piano and playing the violin; while you can hear the quality of the piano regardless, you will not hear the capabilities of a violin unless it is played with skill. This is but one of the reasons why the sounds the violin produces are fascinating to study. Weinreich has explored borrowing sound from a standard violin and imitating it on an electronic violin. He shares his research on violin sound waves and his technique of gathering sound samples from violins, such as the Guarneri Del Gesu ""Vieuxtemps"", and replicating their characteristics.","Instruments, Devices and Systems",Modeling,,,Gabriel Weinreich,"Universtiy of Michigan, USA",104,3:29-5:25 What distinguishes a musical instrument,54:14-54:50 Goal with producing tone color,,,, 1:20,,,,,
Distinguished Lecture,http://youtu.be/DPsPKQ1YSO0,Generale (3),06-12-2012,Putting Together The Puzzle of Multisensory Perception,"Perception, multisensory perception, haptic feedback","The world is full of sensory information - sight, sound, touch, taste, and smell - that our brain must make sense of in order to interact with the world. But what does this process look like and what happens when we are fed noisy, conflicting information? In this talk, Marc Ernst discusses the brain's integration of information from multiple senses, what affects our learning rate when faced with new or conflicting information, and how we calibrate our sensory systems in natural environments. This talk investigates these topics by looking at experiments in laboratory environments, and closes by applying these findings to a real-world situation that asks: Do people really walk in circles when lost in the desert?","Cognition, Perception and Movement",Perception,,,Marc Ernst,"Bielefeld University, Germany",115,"(~8:46 - 12:06, a little more than 3 min, could also end around 10:40, because it gets pretty technical after that) What Would Be the Optimal Way to Integrate Information? --> A look into some data that explains how the brain tends to weigh multiple sources of information from different senses, and what it does when one of the information sources is ""noisy"".","(~20:15 - 23:09) Prior Knowledge Affects Perception --> A look, using some visual illusions, at how we combine sensory information with the knowledge we have of the world to make our best estimate of what's out there.","(~33:24 - 36:07) What Determines Our Learning Rate? -->  Examines why and what influences the brain to learn new mappings quickly, and why it may learn new mappings slowly.","Not really a ""highlight"", but the anecdote of ""do people really walk around in circles when lost in the desert?"" starts at around ~41:45 and goes pretty much till the end of the lecture. It is quite long (because they did three experiments with it), but it's an interesting look at real-world applications of the concepts Ernst discusses in a way that's easier for people with little to no perception background to follow, and is also fairly humourous.",,2h30,,,,,
Distinguished Lecture,http://www.youtube.com/watch?v=PFzy_5RVqF4,West (10),17-01-2013,Topology of musical data,"topology of data, music theory, musical similarity, music information retreival","If every piece of music is considered to be a point in the Euclidean space of all possible pieces, what generalizations could be made about this vast cloud of points? William Sethares's talk on the topology of music considers the geometric features of musical space. Building up from notions of musical similarity or closeness based on western tonal music theory, Sethares leverages the mathematical toolbox of the topological data analysis to expose structures underlying this music.",Music Information Research,Music Information Retrieval,,,William Sethares,"University of Wisconsin, USA",76,"0:42 - 1:38 (56s), Sethares introduces the concept of topological space and describes some of the features which are of interest to a topologist","22:46 - 23:20 (34s), Sethares succinctly describes the methodology he uses to examine the toppological features of a piece of music.",,,,1hr00,,,,,
Distinguished Lecture,http://youtu.be/41cv5uPBWzg,Generale (4),21-02-2013,"Music, Memories, and the Brain","Cognitive pyschology, cognitive neuroscience,  perception","Nostalgia: one of the strongest emotions, tied with memory, that humans experience as we listen to music. In this lecture, Petr Janata examines the movement of music through tonal space using various behavioural and neuro-imaging techniques combined with computational approaches. These methods are used to try to understand how we process tonality, and how it links to a strong experience of music-evoked autobiographical memories. While there are multiple brain areas that interact when memories are experienced with music-listening, the challenge lies in examining how these interactions combine to structure our experience. The first half of this talk focuses more on concepts found in cognitive science/psychology, while the latter half holds more universal concepts.","Cognition, Perception and Movement",Psychology,,,Petr Janata,"UC Davis, USA",114,"(~9:43 - 12:50) A Look at the Torus --> A  quick look, and audience example, of tonality and how a torus (which is repeatedly referred to in this talk) is modelled. (Note: he has some playback issues with the audio example in the first few seconds of this highlight)",(~34:44 - 37:54) Music's Movements in Tonal Space as Represented in the Brain --> Showcases some neuroimaging techniques to examine the pattern of music movement through tonal space in the brain and how it's used as a statistical model for analyzing brain activity that's illicited when people listen to music.,"(~41:30 - 45:32) Music-Evoked Autobiographical Memory -->  A humorous look on a study Prof. Janata did for examining people's different associations with music (Note: the times I put are over 3min. It can end at 44:27, but it's worth it to go to 45:32 for the humour, and is also one of the most easily understandable highlights for those that don't have a cognitive science or psychology background)","(~49:25 - 52:50) Tonality Tracking Responses in the Brain --> A quick rundown of the areas of the brain that are involved in tonality tracking and how it relates to memory-evoking music (iNote: it can end around 52:20,. The time I put is over 3 min, but 52:50 is when he finishes fully explaining this concept)",,3h30,,,,,
Distinguished Lecture,http://youtu.be/Og_V4PkrMEQ,Martins (6),21-03-2013,Violin bows and bowing - action and gestures,"Bow gestures, bowing, bow velocity, bow force, bow-bridge distance, Helmholtz motion","Bowing gestures are highly complex movement patterns that control the sound of a note while preparing for other musical changes. Together, they can affect tone quality, dynamic level, timbre, attack techniques, and other elements of playing. In this comprehensive lecture, theories and common beliefs among musicians are scrutinized. Using live and recorded demonstrations, Dr. Askenfelt explains how the stick-slip phenomenon, the Helmholtz circulating corner, the Schelleng’s triangle, and the Guettler’s triangle relate to bowing and to the coordination of bow velocity, bow-bridge distance, and bow force. The evolution of bowing studies is also discussed, including the innovative approach developed by Askenfelt to measure bowing parameters.","Cognition, Perception and Movement",Gesture,,,Anders Askenfelt,"Royal Institute of Technology (KTH), Sweden",105,"8:38-9:27
Simulation of Helmholtz's motion, a.k.a. the stick-slip phenomenon","16:57-18:21
How does bow hold relate to bow force?","19:25-20:25
Understand how the Schelleng's triangle affects violin playing.","31:32-32:37
Askenfelt's technique to monitor bow-bridge distance, bow velocity, and bow force using a resistance wire.",,3h40,,,,,
Distinguished Lecture,http://youtu.be/LBvmkXzQk48,Richardson (6),18-04-2013,Distributed Creativity in Musical Performance,"creativity, performance, classical music","The belief that all musical performances are creative and are once-in-a-lifetime experiences is a truism. What exactly substantiates creativity? How is creativity encapsulated in a classical music performance? Is it what musicians bring to or add to the musical score? What if a score does not exist? Eric Clarke suggests that we can understand creativity in performance as an interweaving of the possibilities of a score or the cultural model, the tacit performance practices of culture, the perception-action capacities of a performer, the affordances of an instrument, the influence of recordings and other performances, and the affordances of the musical material.",Expanded Musical Practice,Performance,,,Eric Clarke,"Univesity of Oxford, UK",101,1:10-1:34 Presents content of talk,4:46-6:25 Why so much focus on creativity in classical music?,"24:20-25:25 How to understand creativity: possibilities of score/cultural model, tacit performance practices of culter, perception-action capacites of a performer, affordances of an instrument, influence of recordings and other perfmances, and affordances of musical matieral. ",49:35-50:16 The junction where creativity takes places,,1:15,,,,,
Student Symposium KEYNOTE,http://youtu.be/RAdZd4NOGfg,West (3),23-05-2013,A (not so) Brief History of Laptop Orchestras and Ensembles,"laptop orchestra, PLOrk, digital musical instruments, live electronic music","From early experiments with his students building a variety of digital musical instruments, to an international laptop orchestra movement, Perry Cook gives a history of laptop orchestras. Exploiting the viruosity of existing musicians, and extending musical performance through computer mediation, Cook offers a wide overview of his approach to the design of digital musical instruments, and describes the formation of PLOrk and its cousins.","Instruments, Devices and Systems",Performance,,,Perry Cook,"Princeton University, USA",64,"7:35-7:50 (15s), Cook talks about his approach exploiting the viruosity of existing musicians, and extending musical performance through computer mediation","12:27-12:50 (23s), Cook plays a coffee mug.","38:53- about 40:22 (1m29s), Cook demonstrates live coding in Chuck, explaining some of its core philosophy",,,2hr00,"Audio from 12:27-12:50 (23s), Cook plays a coffee mug.","13:14-13:30, musical excerpt after Phillip Glass","38:53- about 40:22 (1m29s), Cook demonstrates live coding in Chuck, explaining some of its core philosophy",,
Student Symposium KEYNOTE,http://youtu.be/7GepqzENM-I,West (4),23-05-2013,"Interactivity, shminteractivity: In search of the expressive computer","interactive music, expressivity, musical gesture, computer music","Christopher Dobrian comments on his experiences developing interactive computer music. Whereas human musicians are charismatic, creative, expressive, and lively, in order for a computer to musically interact on stage, these traits must be simulated algorithmically. Dobrian shares his frustration with this charisma gap, and some of the approaches he has taken to try to close it. How can computers be made musically expressive? When is it more appropriate to fake it? What is it that makes a musical gesture meaningful in the first place? Dobrian considers these questions and more in this exciting keynote.","Instruments, Devices and Systems",Interaction,,,Christopher Dobrian,"University of California Irvine, USA",94,"24:50 - 25:22 (32s), Dobrian talks about the gap in charsma comparing humans and computers onstage.",32:27 - 33:15 (48s) Dobrian offers a definition of human-computer musical interaction compared to mere reaction.,"35:05 - 35:57 (52s) Dobrian suggests that fake interaction may be as good or better than computationally simulated interaction, and encourages composers to consider why they might use a particular piece of technology",,,2hr00,"excerpt from Entropy, 13:11 - 15:20 (2m09s), the ending is particularly nice","excerpt from There's Just One Thing You Need to Know, 22:38 - 24:38 (2m)",,,
Distinguished Lecture,http://youtu.be/UJBq44pnUoo,Aspinwall (4),12-09-2013,Music understanding and the future of music performance,"Human-computer interaction, computer music, music technology","Roger Dannenberg gives us an overview of human-computer interaction for music performance, and how innovation in this field could contribute to artistic expression and commercial products. Using examples of his and his colleagues’ research, he highlights the capabilities of actual computer systems for accompaniment, style classification, score alignment, onset detection and sound synthesis. Professor Dannenberg presents various research challenges in the field and finally, he talks about how building intelligent machines could re-shape the way we learn, perform and share music. Ultimately, enriching the musical experience for millions of people.",Expanded Musical Practice,Interaction,,,Roger Dannenberg,"Carnegie Mellon University, USA",91,[00:47 - 01:18] It introduces the talk and sets an optimistic tone to the narrative,"[38:35 - 39:50] This idea It ends on a cliffhanger, makes you want to listen to what he’s going to say next. ","[45:41 - 47:34] This video is a culmination of his research, years of work applied to a live musical performance.","[50:53 - 51:00] This idea wraps up the lecture, draws parallels between other art forms and computer music. It closes with an optimistic tone as the first one did.",,4:00,,,,,
Distinguished Lecture,http://youtu.be/iQuCpLuhBWk,Rong (2),17-10-2013,Acoustics and contemporary music,"Wind instruments, contemporary, mechanics","One of the most important elements of contemporary music is acoustics and novel ways of producing sound. Caussé discusses the ways in which 20th-century composers integrate the mechanics behind creating sonorities into writing music that is radically different from historical genres, including mutes for brass and clarinet, microintervals (intervals smaller than a semitone), multiphonics, and virtual instruments. Many different approaches, such as the addition of devices onto an instrument, physically changing the embouchure, and the development of new techniques are explored through new methods of measurement and research. As well, software such as Modalys is now employed to explore the hybridization of acoustic and digital music making.","Instruments, Devices and Systems",Acoustics,,,René Caussé,"IRCAM, France",107,"6:50 - 9:00 The microintervallic system was used by composers suchas Ligeti by employing a physical device in order to expand the capabilities of the instrument. These devices also gave way to possibilities for ""split personalities"" where an instrument was able to produce different types of sound through different methods.",30:05 - 32:30 Radiation imaging was used for measurement of frequency in a saxophone - a very meticulous and detailed process that resulted in a unique model of saxophone mechanics.,36:30 - 37:40 Computers have been able to reproduce and synthesize sound based on physical principles that have been programmed into them - have computers become comparable to the physical act of music making?,46:49 - 48:18 The quality of both wind and percussion instrument tone can be mathematically plotted in order to analyze aspects like sound decay and different partials of the instrument.,,2hr 30,,,,,
Distinguished Lecture,https://www.youtube.com/watch?v=i_juIZq46gI,Aspinwall (3),14-11-2013,Semantic audio: Combining semantic web technology with audio analysis,"semantic audio, metadata, music analysis, music technology","Mark Sandler takes us through a ten-year journey of research in the field of semantic audio. Using various project examples, he presents how this research is connecting pieces of data, information, and knowledge that surrounds the world of music. With the goal of not only extracting meaning from audio, but to be able to use it to create musical tools and experiences. Professor Sandler talks about the evolution of the field starting from expert generated metadata in applications like Pandora, the current state of content-based metadata and a look into the second generation of digital music applications that use standardized semantic metadata.",Music Information Research,Music Information Retrieval,,,Mark Sandler,"Queen Mary University London, UK",104,"[58:05 - 01:00:32] These are the major challenges of the field, he goes into more detail during the lecture and is a good overview of the topics he talks about.
",[17:33 - 19:01] He shows his projections for the future of semantic audio,[01:04:21 - 01:06:11] This is the conclusion of the talk where he arrives at a new (personal) definition of what semantic audio should be. ,,,4:00,,,,,
Distinguished Lecture,http://youtu.be/_G68Q4gkOMc,West (5),23-01-2014,Spatiality in Acousmatic Music,"acousmatic music, music composition, spatiality, space","“Spatiality” refers to all those factors that contribute to the experiencing of space. In this talk, Denis Smalley elaborates on his theory of spatiality, describing the way that the sounds of acousmatic music evoke transmodal physical experiences, including motion, depth, and scale. Not just related to the perceived position of a sound in space, Smalley's theory of spatiality considers the whole acousmatic ""image"", the sources implied by the sounds or imagined by the listeners, and the spectral properties of the sounds. Smalley shares insight into his approach to composition with space in his acousmatic compositions.",Expanded Musical Practice,Acoustics,,,Denis Smalley,"City University, UK",95,"6:19-7:17 (58s), Smalley describes the way in which listening to acousmatic music is a transmodal sensory experience","42:03 - 42:53 (50s), Smalley talks about the importance of understanding spatiality for composers",42:58 - 43:38 (50s) Smalley suggests that space be given a special focus in composition,,,2hr00,20:16 - 22:22 (1m6s) excerpt from Valley Flow,30:20 - 32:46 (2m26s) another excerpt from Valley Flow,,,
Distinguished Lecture,http://youtu.be/JBhVh-yob38,West (6),27-03-2014,A listening tour of musical portraits and sonic landscapes,"sonification, collaboration, sound installation","Chris Chafe gives an overview of his work in computer music, ranging from concert pieces to investigations about how we imagine sounds in our head. The threads involve joint work with biologists, instrument builders, neurologists, conductors, students, cargo ship captains and massive groups of online listeners. From works for musicians with fixed electronic accompaniment to real-time sonification of environmental data, Chafe's work encompasses a wide range of approaches to computer music. Some of the work is pure music, some of it part engineering and observation.","Cognition, Perception and Movement",Computer Music,,,Chris Chafe,"Stanford University, USA",85,"6:37 - 7:00 (23s), Chafe identifies the thing he strives to evoke in the audience of his sound installations",10:48 - 11:31 (43s) Chafe gives an overview of some of his work in sonification of data,20:50 - 21:57 (1m07s) excerpt from Oxygen Flute,,,1hr00,3:01 - 4:39 excerpt from Free Motion,8:01 - 8:58 excerpt from Near the Inner Ear,20:50 - 21:57 excerpt from Oxygen Flute,28:04 - 29:24 excerpt from Chopper,
Distinguished Lecture,http://youtu.be/PKpRaqjbD-g,Generale (5),17-04-2014,Music Learning Through Multiple Lenses,"Music Education, Learning, Teaching Methods","What happens in a learner's mind that leads them to understanding, or not understanding, a concept? What leads learners to be able to do something, or not do something? How can educators change a learning environment and the way they teach to reflect what learners experience outside the classroom? In this lecture, Dr. Robert Duke speaks about important considerations for not only effective music learning, but effective learning across all disciplines. Drawing from examples such as case studies, and often from his own humorous personal experiences, Dr. Duke highlights the importance of teaching attitudinally, with room for error-making, and with clear visions and goals in order to engage students to learn deeply. ",Expanded Musical Practice,Education,,,Robert Duke,"University of Texas, USA",112,"(~6:00 - 9:10) Effective Expression --> Using a popular YouTube video, Dr. Duke showcases that students, even the very young, are capable of effectively expressing themselves in music and other disiciplines (this video is also referenced through the lecture)","(~11:57 - 15:10) The Brain is Not a Flash Drive --> A look into a misconception on how our brains store information that we learn, and how we can change this to facilitate deeper, more memorable learning. (It runs a little longer than 3 min because he ends with a kind of long sentence after)","(~27:14 - 29:50) A Quick Look at Dr. Duke's Work --> Offers a very quick overview of some of the Dr. Duke's work and work done at the University of Chicago, related to teaching that focuses on the effects of a musician's movements rather than the movements themselves. ","(~37:00 - 39:44) Training Wheels --> This segment highlights how error-making contributes to a student's depth of learning, and how teachers can incorporate this into the learning environments they build.",,2h30,,,,,
Student Symposium KEYNOTE,http://youtu.be/WGnUrCNdH88,Richardson (2),07-05-2014,Scordatura: on re-mapping the body to sound ,"instrument creation, instrument modification, scordatura, electronic instrument, composition","What creative doors open when we employ scordatura to re-explore the possibilities of musical instruments? Likewise, what opportunities become available with the introduction of completely new instruments? When we remove musicians from their well-learned accustomed modes of musical performance, creative potentials are fueled. Trueman discusses his multifaceted work as a fiddler, inventor, and composer with new and reconfigured instruments. From composing with his Hardanger d’Amore fiddle played with alternative tunings to inventing new musical instruments and co-founding the Princeton Laptop Orchestra, his work involves “leveraging and subverting existing, hard-earned embodied modes of expression” for the purpose of providing embodied creative spaces. ","Instruments, Devices and Systems",Design,,,Dan Trueman,"Princeton University, USA",101,2:08-2:37 goal for presentation and intro of term: scordatura.,"34:31-36:44 benefits of one of his invented instruments, opportunities new instruments provide, and ""what now?"" (What to do with these newly invented instruments?), and introduction of new ensemble ",53:58-54:30 What should we aim for in designing new instruments? ,,,2hr 15m,,,,,
Distinguished Lecture,http://youtu.be/GAzVZOZe2f8,Rong (1),30-09-2014,Music Recommendation and Discovery at scale,"music recommendation, computer programming, psychology ","Douglas Eck, of Google USA, traces the evolution of musical formats from CDs to digital albums to online streaming – developments shaped by the debuts of devices like iPods and iPhones. By distinguishing between the situations in which we have low and high engagement with music, he discusses the importance of smart user design and the role of neuroscientists, psychologists, and musicologists in the complex system of music recommendation. Three technical aspects are instrumental in suggesting music to listeners: collecting other users’ preferences to learn about possible similarities in music taste, the social knowledge and connections of musicians themselves, and audio signal processing that tags audio that sound similar together.","Cognition, Perception and Movement",Psychology,,,Douglas Eck,"Research Scientist, Google, USA",109,"8:01 - 8:22 Once someone starts listening to music with a service such as Spotify or Pandora, they are more likely to be drawn in and continue to branch off and listen to new music - so the way to expose music to more users is just to get them started on platforms like these.","13:39 - 14:01 Many of our cultural connections to music have been lost as we transition to digitalized forms of music, such as the courtship rituals of making mixtapes or browsing in record shops. Eck believes we should continuously be striving to get some of this connection back.","34:43 - 36:06 Linear algebra is used extensively to calculate the popularity, niche, and ranking of specific musical tracks. This can draw parallels between artists and assist in music recommendation.","43:16 - 44:40 Auditory programs are able to analyze similar-sounding ""clusters"" of audio that may recur in the same genre of music.",,2hr 30,,,,,
Distinguished Lecture,http://youtu.be/5pT5i1Fm3kw,West (2),13-11-2014,Growing a global business from a small factory,"music instrument business, guitar manufacturing, entrepreneurship, marketing","Robert Godin tells a story from humble beginnings building a few guitars with an ex-window maker to a global business manufacturing thousands of guitars at half a dozen factories around Canada. Godin shares some of the important lessons he has learned over the years, recounting some of the mistakes he made and some of the opportunities he took full advantage of and offering his insight into what is most important when building and selling a musical instrument. With excitement and enthusiam, Godin describes the way technology has changed his business, from online retail to robotic machinery, despite himself never owning a personal computer.","Instruments, Devices and Systems",Business,,,Robert Godin,"Godin Guitars, Canada",103,"18:49-19:11 (22s), Godin emphasizes that marketing an instrument as as difficult as manufacturing an instrument","32:16-32:53 (37s), Godin shares a surprising insight: the sound of an instrument is only the third thing a guitarist considers when buying a guitar, after the look, and the feel.","45:23-46:29 (66s), an anecdote, an old Norman guitar made in 1974 sold for 10 times its original price in 2014. Compare and contrast with the instant obsolescence and disposability of consumer electronic.","57:53-58:13 (20s), Godin shares his excitement for the future, talking about the incredible advances in their manufacturing processes using state of the art industrial robotics.",,1hr13min + 1hr30,,,,,
Distinguished Lecture,http://youtu.be/T2JnSfpFJ24,Martins (2),12-02-2015,Apollo's gift and curse: Acquisition and loss of skilled movements in musicians,"Brain, music performance, physiology, focal distonya, expertise, music practice, performance-related musculoskeletal disease","In an interesting analogy to the mythological figures of Apollo and Marsyas, Dr. Altenmuller discusses how music can be both beneficial and harmful to brain plasticity, which is the functional and structural adaptation of the nervous system to processing of relevant stimuli. Sharing his lifework, this musician-physician highlights some of his successful studies on musicians, including some players from Berlin’s Philharmonic and a French horn player without arms! With a physiological perspective, these studies encompass contrasting effects of music practice, from the motor refinement achieved with expertise to the causes, triggering factors and available treatments for focal distonya.","Cognition, Perception and Movement",Performance,,,Eckart Altenmüller,"Hannover University of Music, Drama and Media, Germany",98,"11:15-12:15
Real-time MRI of four Berlin Philharmonic players.","24:12-25:29
Impressive Mozart performance by 17-year-old French horn player Felix Klieser.",,,,3hr,,,,,
Distinguished Lecture,https://youtu.be/B2cWQqfCqLA,Gjerbic (2),19-03-2015,Musicology centered design,"human-centered design, survey, music researchers","In this lecture, Frans Wiering discusses the long-standing discrepancy between the technological needs of musicologists and the products designed by software engineers. Attributing this mismatch to a lack of sensitivity to the needs of music researchers, Wiering advocates a “human-centered” approach to the design of new technologies. Careful study of the stakeholders lies at the center of this approach: what do musicologists do and value? Wiering provides preliminary results of a 500+ participant survey, demonstrating that music researchers are frustrated with the current design of many software packages. Engineers need to design new technology with musicologists, interactively, not for them.",Music Information Research,Design,,,Frans Wiering,"Universiteit Utrecht, Netherlands",100,"Wiering discusses the advantages of “human-centered design” in interactive system design, emphasizing that this model does not presuppose an existing technology, but begins with a problem and designs the technology to solve that problem (29:19–30:33). ","One of the most significant preliminary results of the survey is that in regards to “rewarding and frustrating experiences [with existing technology], frustration is most notable” (41:59–42:19).",,,,3hr,,,,,
Distinguished Lecture,https://www.youtube.com/watch?v=zrpUDuUtxPM,Aspinwall (6),16-04-2015,Sound reproduction – art and science/opinions and facts,"loudspeakers, sound recording, music perception, music technology","In this lecture, Floyd Toole presents a scientific approach to sound reproduction evaluation. He talks about how subjective and technical measurements have an important relationship to psychoacoustic perception, which has a major impact on evaluation results. Mr. Toole highlights the value of repeatable tests. Using various examples, he introduces the best practices that he and his colleagues developed to ensure that the measurements are an accurate representation of a product’s timbral performance. He highlights how challenges such as room acoustics can affect the listeners’ perception of the product and, lastly, he shares his perception of what kind of technical information should be provided to the consumer.","Cognition, Perception and Movement",Perception,,,Floyd Toole,"Consultant to Harman International, USA",106,[05:54 - 8:20] He introduces the concepts that are important to listening tests and shares his personal experience as how he was introduced to these.,[56:15 - 56:47] States his philosophy in a friendly way,[57:23 - 59:58] Puts together the little bits of information he talks about during the lecture and shows the framework that they currently use,[1:07:14 - 1:07:42] An interesting remark on how manufacturers provide technical information of their products.,,4h,,,,,
Distinguished Lecture,https://youtu.be/qASbgvulDSc,Tirumala (2),24-09-2015,Frontiers of music technologies – singing synthesis and active music listening,"Vocaloid, VocaListener, VocaWatcher, Singing Synthesis,  Automatic Music analysis, Music undertsanding, Songle, Songrium","Masataka Goto unveils a world of futuristic singing synthesis engines that hopes to pave the way into the world of computer-composed internet hits and virtual pop stars performing live concerts that can respond to popular preferences among audiences. In a similar context, he continues to touch on the subject of music-understanding technology centered around hypothetical scenarios in the future, where virtual singers could evoke human emotion through their musical creations, or other kafkaesque ideas like the role of a non-human audience in the future. He then continues to present music-understanding technology as a means of cataloging the infinitely growing collection of original and derivative content created by users and computers.","Instruments, Devices and Systems",Artificial Intelligence,,,Masataka Goto,"National Institute of Advanced Industrial Science and Technology (AIST), Japan",110,8:06 - 8:56: Hatsune Miku Phenomenon using virtual singing synthesis embodied by avatars as part of live concerts,10:50 - 12:15 : VocaListener and features,"22:10 - 23:21 : In the future, can computer generated music evoke emotional responses in humans? Hypothesis for music-induced deep emotion.","31:30 - 32:23: Songle - Music learning, and exploration.",,2hr 40m,,,,,
Distinguished Lecture,https://youtu.be/mxO_z3iJAZI,Generale (2),22-10-2015,The Future of Immersive Technologies,"Perception, Immersive Technology, Neuroscience","How we interact, engage with, and perceive the world offers important insight in developing immersive technologies. In this talk, Poppy Crum, Chief Scientist at Dolby Laboratories, speaks about investigating how humans process information, biophysical reactions, and our own personalized interactions with the world to help us create holistic and more engaging immersive technologies. Existing technologies and processes are shown to illustrate the direction and potential of future immersive technology. This lecture examines the importance of explaining perception theoretically, computationally, and quantitatively in order to build immersive experiences that we can engage with that accurately represent the intent of its content's creators.  ","Instruments, Devices and Systems",Immersion,,,Poppy Crum,"Dolby, USA",101,(~9:08 - 12:03) Insight on How We Process Info using the McGurk Effect and How Perception is Malleable -- > Basic ideas and concepts from this introduction on perception will be further touched upon in later points of this talk.,(~26:11 - 29:30) How Does Our Body React to Experiences and What Makes an Experience Immersive? A Study Using Thermal Imaging - An interesting look at how our biophysical reactions (ie. The sensation of feeling heat) can contribute to us having an immersive experience.,"(~45:33 - 49:33) Our Own Personalized Filters - HRTFs: What is it, its challenges, and how can it help us build immersive experiences? --> A quick look on HRTFs (what they are, their importance, and where they are used) that illustrates how our experiences are unique and individualized, but help contribute to experiencing an immersive environment.","(1:04:20 - 1:07:25) - A Look into Dolby Atmos and Object-Based Audio --> With more and more movie theatres making a move towards Dolby Atmos, this segment highlights its technology as well as some challenges that researchers and developers still face when creating believable, immersive experiences.",,3hr ,,,,,
Distinguished Lecture,https://youtu.be/93Fa5gC1QSk,Martins (1),05-11-2015,Facing the music: Employing science and technology to enhance professional training,"performance anxiety, performance enhancement, physiology, practice, stress","At the Royal College of Music, the Centre for Performance Science researches ways to assess and enhance all kinds of human performance through a multidisciplinary approach. In this mission, music is the main tool to understand the effects of stress. Aaron Williamon discusses three studies on the anxiety in music performances and how physiological parameters compare in individuals before and during performance. Different sample sizes and analysis techniques are employed. Results show that the pre-performance period is the optimal for an intervention. To minimize anxiety and bridge the gap between dull practice rooms and challenging concert halls, a low-cost practice simulator is presented.",Expanded Musical Practice,Practice,,,Aaron Williamon,"Royal College of Music - Centre for Performance Science, UK",103,"23:49-26:16
Williamon explains why low frequency-high frequency ratio, when looking into heart rate variability, may not be the best technique to understand stress response.","43:33-44:25
Take a look at the demonstration of the practice simulator. It features an interactive audience and panel. The equipment has been tested by over 300 musicians as well as students from other disciplines.",,,,3hr34m,,,,,
Distinguished Lecture,https://youtu.be/U46X-cSRA2I,West (1),25-02-2016,Moving parts: On structure and chaotic actions in the design and build of my computer-based music(s),"algorithmic composition, the grottesque, Max/MSP, Open Music, CNMAT, collaboration","Edmund Campion describes his life as a composer, and the development of his compositional approach which brings together the traditions of western music composition and new media technology. Campion describes his aesthetic tendencies and surveys a number of his projects from 25 years of work as a composer, including some of the algorithmic processes used in his composition, and briefly touching on some of the tools developed at CNMAT for artists and composers. Highlighting the importance of collaboration between artists, scientists, and engineers, Campion suggests a path forward toward new aesthetic terrains in music and art.",Expanded Musical Practice,Computer Music,,,Edmund Campion,"CNMAT, University of California at Berkley, USA",96,"8:21-8:29 (7s), Campion mentions an uncanny valley between the interest of scientists and researchers and those of musicians and composers.","24:27-25:07 (40s), Campion beautifully describes his perspective on the nature of music.","56:04-56:21 (17s), Campion describes the scale of the productions he works with, and the unique collaborative atmosphere","1:00:59-1:01:39 (40s), Campion elaborates on this belief that ""collaboration is the key, and the goal is symbiosis""",,2hr35m (to watch 1hr03m; to review 1hr30m); additional 1hr30,"Audio from 27:23-27:56, interesting morphing acousmatic sounds traverse a continuum from noise to notes in an exceprt from the piece ""the other""","Audio from 36:19-37:34, exerpt from Wavelike and Diverse, percussion instruments in intersting algorithmically determined rhythmic patterns","video from 40:42-42:27, a simulation of the ensemble contemporaine with animated colored bubbles in a curious looking Max patch.",,"I would suggest however that it may be useful for the editors of the highlights reels to identify sections with interesting audio or video that might be used as b-roll or background music in addition to highlights in the lecture; particularly for lectures which include interesting audio excerpts, I can imagine personally finding this very useful.; SHOULD RAs be noted?"
Distinguished Lecture,https://youtu.be/iwOaYxSJGqI,Aspinwall (5),24-03-2016,Give me limits!,"computer music, sound recording, music production, music technology","Robert Henke presents two perspectives on computer based music production. The first, being the creative side, where he is the user of these technologies to aid his artistic expression. Later he explores the other, in which he is the person involved in creating these tools for others. Mr. Henke delves into how the invention of recording became a new art form in itself and has evolved to what we know as computer music. Furthermore, he talks about how music is developing and taking shape in a post-computer generation where possibilities are seemingly endless. Finally, he shares how he envisions future tools will be developed to serve new creative possibilities.",Expanded Musical Practice,Computer Music,,,Robert Henke,"Independent audiovisual installation artist and musician, Berlin, Germany",109,"[01:58 - 3:28] He describes how music is traditionally created, during the talk he references this to contrast his argument",[26:42 - 29:22] He exemplifies how the excess of tools becomes counterproductive to his creative process,[36:18 - 38:13] He talks about how coding can become a personal compositional tool  ,[49:45 - 52:18] He resolves his idea of dealing with over-abundance of tools.,,4h,,,,,
Distinguished Lecture,https://youtu.be/4A99fAHNL50,Aspinwall (2),21-04-2016,"Virtual musical Instruments in virtual rooms - what's real at all?
","virtual acoustics, virtual reality, simulated spaces, immersion","In this talk, Michael Vorländer explores the current state of virtual acoustics technology. He starts the lecture with a brief explanation of how virtual sources are generated, shaped and reproduced using computer models. Afterwards he shows how these models are applied to virtual reality content to achieve real time immersive experiences. Mr. Vorländer demonstrates some of his immersive projects including a 3D reconstruction of the Montreux Casino in Switzerland. He finishes by talking about the challenges in the field and gives an overview of the current methods for quantifying and evaluating immersion.","Instruments, Devices and Systems",Immersion,,,Michael Vorländer,"RWTH Aachen University, Germany",92,[2:40 - 3:41] He explains how virtual reality representations of data can help people with non-technical background understand complex data,[06:45 -07:04 ] He shows the overview of the lecture,[51:25 52:30] He states the advantages of multidisciplinary collaboration using virtual reality for data visualization,,,3hr,,,,,
Distinguished Lecture,https://youtu.be/hRA0Yqfu9oM,Richardson (1),20-10-2016,What Makes us Musical Animals?,"musicality, beat perception, beat induction, beat synchronization, relative pitch","Musicality can be defined as a naturally developing set of traits based on and constrained by our cognitive and biological system, while music is a social and cultural construct built on that very musicality. Without the skills of musicality, there is no music. All humans share a predisposition for music. As stated by the hypothesis of multicomponent musicality, humans and animals may share some of the skills necessary for musicality, and other qualities may be species specific. Honing explores the components of musicality, particularly beat induction, and the question of which musical traits humans and animals share.","Cognition, Perception and Movement",Perception,,,Henkjan Honing,"University of Amersterdam, Netherlands",97,16:06-16:24: What are possible components of musicality and how are we studying them in animals.,18:24-20:30: introduces relative pitch and beat induction.,"56:26-57:16 Summary: We share a predispostion for music, beat perception and relative pitch are building blocks of musicality, and comparative research is a promising method.",,,2hr 55m,,,,,
Distinguished Lecture,https://youtu.be/HvmD4-5aRto,Reesor (2),23-02-2017,"The Instrument, the Player and the Maker","Transitional flute, Musical acoustics, Instrument design ","Benoit Fabre presents cumulative flute-centred research in musical acoustics that examines the relations between maker design, instrument physics, and player technique, within the context of musical purpose. He shows a new transitional flute that he has developed in conversation with the research. Fabre details the flute player’s basic task of crafting particular jet streams according to the instrument’s resonator and desired tones. He illustrates that the execution of the basic task is dependent on its musical context, where musical intention is correlated to respiratory effort and organized by time shapes, and time shapes depend on one’s musical understanding rather than technique. Further, musical line direction is closely correlated to respiratory effort, which leads Fabre to present a new hypothesis for further study.","Instruments, Devices and Systems",Design,,,Benoit Fabre,"Sorbonne Universités - UPMC, France",122,Mirror neuron hypothesis (36:20-38:10): Explanation of a new area of study in response to the cumulative research.,Predicting sound consequences of design choices (41:25-43:55): Description of useful considerations for an instrument maker.,Demonstration of new transitional flute (46:10-46:40): Performance of a Schumann oboe excerpt.,,,6hr45,,,,,
Distinguished Lecture,https://youtu.be/RcCFzaaImYE,Gjerbic (1),20-04-2017,Giving people control of our most important human sense—hearing,"hearing, control, active manipulation, social interactions  ","In this lecture, Dan Gauger details the mechanics and motivation behind the BOSE QC30 headphones. The QC30 model allows the user to adjust the level of noise cancellation on a near-continuous scale, enabling active manipulation of their sonic environment. This technology grants total control to the user over their sense of hearing, the sense, Gauger argues, humans have the least amount of control over. Not only does this capability increase comfort and productivity, but allows complete mobility between a fully-immersive sonic environment and a “social earphone” condition that allows the user to equalize their external world, thus enriching social interactions.","Instruments, Devices and Systems",Interaction,,,Dan Gauger,"BOSE, USA",100,"Gauger posits the claim “hearing is our most important human sense” and provides support through behavioral research, quotes from historical figures, and a powerful thought experiment posed to the audience (41:00–43:12). ","In his closing remarks, Gauger reiterates “compared to our other senses, we have less inherent control over [our hearing],” and summarizes the technologies employed in the QC-30 earphones (49:53–50:37).",,,,3hr,,,,,
Student Symposium KEYNOTE,https://youtu.be/5wCH_Y1V7cI,Reesor (1),19-10-2017,Learning to live with error? Some reflections on trying to use computers to do musicology,"Musicology, Computational musicology, Music information Retrieval, Chroma","Prof. Tim Crawford discusses his cumulative work in developing computer-based musicology tools as a basis from which future tools for musicology can be formed. Crawford’s vision was to develop tools which could allow one to find music information within a corpus, as with a librarian. Alongside an interdisciplinary music data research group, the group’s work catalysed a hybrid discipline called Music Information Retrieval. The driving force of this field is to harness tools that can search across data within a corpus. Crawford advocates the use of MIR tools within a semantic framework, thus holding the features of data in conversation with the external factors that surround them. Tools illustrated: audio searching across modern and historical recordings, and score searching across early music prints.",Music Information Research,Music Information Retrieval,,,Tim Crawford,"Computational Musicology, Goldsmiths University of London, UK",123,Using Chroma search to find selections of modern audio within large works (45:55-47:50).,Using Chroma to find audio selections across many performances of the same work (49:50-51:50).,Using Chroma to search for historical audio selections (52:55-54:35).,Explanation of searching for a selection of an early music score file across a corpus (57:55-1:00:00).,,4hr15,,,,,
Distinguished Lecture,https://youtu.be/OtAbY43wRKA,Generale (1),19-10-2017,"Recital Halls, Rehearsal Rooms, and Research Spaces","Acoustics, Room Design, Acoustic Treatment","With certain intended room purposes come challenges and factors that acousticians, consultants, and architects must consider when designing a space. In this distinguished lecture, Joseph Myers of Kirkegaard Associates offers an introduction to room acoustics and focuses on three types of spaces: those used for performance, rehearsal, and research. Using examples, Myers explains design considerations catered to each space regarding reflections, room treatment, sound colour, and reverberation. The talk closes with the design plans for McGill University's Multi Media Room (MMR), a space intended for performance, rehearsal, and research.","Instruments, Devices and Systems",Acoustics,,,Joseph Myers,"Kirkegaard Associates, USA",89,(~8:40 - 11:51) Introduction to Sound and Acoustics -- > Concepts introduced in this quick overview of sound and acoustics will be later expanded on and applied to designing a room.,"(~28:00) Recital Halls, Rehearsal Rooms, and Research Spaces (note: See below for start times of hall demos/""Sub-highlights"") --> A look into the design considerations for rooms of different purposes. See below for the ""subhighlights"" of the three different kinds of rooms.","(~52:33 - 55:33) Designing the McGill's Multi-Media Room (the MMR), a Space for Performance, Rehearsal, and Research --> Modelled from EMPAC, this segment highlights the challenges in designing a multipurpose room: McGill's MMR.",,,2hr,,,,,
Distinguished Lecture,https://youtu.be/5SqIRTyVQgg,Aspinwall (1),09-11-2017,YAMAHA's musical instruments and audio products as DSP applications,"instrument design, product design, music technology","Toshifumi Kunimoto talks about his career, dedicated to designing groundbreaking instruments for Yamaha. He presents a four decade retrospective of his work, highlighting the challenges that were encountered with each of the projects he worked on. After explaining how these ideas were developed, he evaluates each instrument’s strengths and weaknesses regarding sound, playability, user enjoyment, development time and cost. He concludes his lecture by highlighting the various approaches that can be taken to design a successful product.","Instruments, Devices and Systems",Design,,,Toshifumi Kunimoto,"YAMAHA, Japan",77,[02:22 - 04:30] A very basic and friendly introduction to the concepts behind synthesis methods,[37:43 - 39:41] He wraps up the presentation by sharing some ideas regarding how to approach new technologies for commercial purposes,,,,3.5hr,,,,,
Distinguished Lecture,https://youtu.be/HvXMnRU96_E,Tirumala (1),13-12-2017,Recombinant Music: Generative Approaches,"allegorical, recombinant, architecture, generative music, re-embodied intelligence, computational creativity, interactive art installations,","The talk weaves together some of the previous works of the speaker, Bill Seaman, in collaborations with other renowned artists such as Pauline Oliveros, Sonke Johnsen, etc., and their efforts to produce artwork by recombining  elements from other artworks. The works presented are primarily interactive art installations and compositions that were born of strategic recombinations of media forms like music (or sound), image, speech and text, done in real-time with the help of generative techniques and artifical intelligence machines.",Expanded Musical Practice,Artificial Intelligence,,,Bill Seaman,"Duke Trinity College of Arts and Sciences, USA",79,5:37 - 6:32: Using AI in collaboration with John Supko,15:00 -  16:21: Passage Sets,19:29 -  20: 37: Meta Timepiece,"21:56 - 22:49, 25:00 - Machines creating art.",,2hr,,,,,
Distinguished Lecture,https://youtu.be/SyixalrH7xo,Martins (11),02-01-2018,Composing the real,"extended vocal techniques, electro-acoustics, sound morphing, sonic qualities","Trevor Wishart writes music using speech but in a unique and unconventional way. Instead of focusing on the narrative content he studies the sonic qualities of syllables from multiple languages and manipulates them aiming for a balance between technical and musical aesthetic exploration. Through the morphing of the voice he is then able to mimic the sound of bees or even bells. In his lecture, he shares these creative and compositional processes as well as many excerpts of his music. The details include challenges with collecting material for his compositions, some rather funny anecdotes, and the software programming he does himself in order to accomplish his musical ideas.  ",Expanded Musical Practice,Composition,,,Trevor Wishart,"Composer & Performer, UK",108,"4:08-4:58 
Excerpt from a piece that uses the subharmonic of the voice and morphs it into the sound of bees.","5:29-6:39 
Wishart walks the audience through his piece, explaining the compositional process he used to achieve a bell-like sound based on a sang syllable.","15:57-18:06 
Example of th intricate creative process adopted by Wishart, from question (concept) to realization (sonic representation); in this case, the lengthening  of an iterative syllable",,,3hr,,,,,
Distinguished Lecture,https://www.youtube.com/watch?v=dQt1yPeyV38,,15-03-2018,"Gesture: a Language to Sense, Express, Control","sing language,  theater, musical gestures, avatar, motion capture","Gesture is used as a means of communication in a variety of circumstances, however deeper knowledge of the mapping that occurs between the language units and the motion is required. Gibet proposes a perception/production approach for explaining motion and language production/comprehension related to sign language, theater, and musical gestures. She offers a methodological approach for the extraction of meaningful components of motion in the decoding process and use of these components to re-synthesize motion in the encoding process. Beyond this, Gibet describes the tools developed for specific analysis/synthesis models adapted to gestures: avatar technology as well as the synthesis models and methods employed.","Cognition, Perception and Movement",Gesture,,,Sylvie Gibet,"University of South Brittany, France",103,0:43-1:20 Overview of talk: skilled human gestures,5:26-6:19: Content/Outline of the presentation (movement notations/languages and perception of biological motion) and focus of the research,17:03-18:30: Gibet proposes a perception/production approach,"56:14-57:34: Conclusions of presentation on sign language studies, physical theator, percussion, and conducting. ",,40 minutes (6/15)         1:15 (6/16),,,,,